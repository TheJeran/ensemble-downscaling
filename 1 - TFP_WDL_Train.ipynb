{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e65c58-9bb9-4b9f-b0ae-13bbb3b6a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.utils import class_weight\n",
    "from scipy.stats import pearsonr\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "def nll(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)\n",
    "def ubrmse(ground,pred):\n",
    "    bias = np.mean(ground-pred)\n",
    "    rmse = np.sqrt(np.mean((ground-pred)**2))\n",
    "    ubrmse = np.sqrt(rmse**2-bias**2)\n",
    "    return round(ubrmse,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73640ce5-2658-4416-b91c-ee1b09b29cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pickle.load(open('Datasets/all_df_final.pkl','rb'))\n",
    "all_rf = all_df.copy()\n",
    "all_df['NDVI_500'] /= 10000\n",
    "all_df['NDVI_250'] /= 10000\n",
    "all_df['LST_11'] /= 5000\n",
    "all_df['LST_11'] -= 2.7315\n",
    "all_df['precip'] /= 1000\n",
    "all_df['sand'] /= 100\n",
    "all_df['clay'] /= 100\n",
    "all_df['ph'] /= 100\n",
    "all_df['ET'] /= 1000\n",
    "all_df['dem'] /= 10000\n",
    "all_df.dem = round(all_df.dem,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa8aac7-3eca-401a-958e-a73e84019096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('Datasets/val_df.pkl')\n",
    "cond = all_df.index.isin(test_df.index)\n",
    "train_df = all_df[~cond]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36427e6-e6b7-465c-8814-e219ebc9fc98",
   "metadata": {},
   "source": [
    "## TFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174c74dc-c8eb-4125-a2eb-0ba5d28ede6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prior_trainable(kernel_size, bias_size=0, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(n, dtype=dtype,name='prior_var'),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "          tfd.Normal(loc=t, scale=.5),\n",
    "          reinterpreted_batch_ndims=1),name='prior_lam'),\n",
    "    ])\n",
    "\n",
    "def posterior_mean_field(kernel_size, bias_size=0, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    #c = np.log(np.expm1(1.))\n",
    "    return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(2 * n, dtype=dtype,name='post_var'),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "          tfd.Normal(loc=t[..., :n],\n",
    "                     scale=tf.nn.softplus(t[..., n:])),\n",
    "          reinterpreted_batch_ndims=1),name='post_lam'),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc754220-bcc2-4dd2-95e9-2bb8bb2cdf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model(inputs=7,train_len=100):\n",
    "    model = keras.Sequential([keras.layers.Input(inputs,name='Input'),\n",
    "                          keras.layers.Dense(inputs,'sigmoid',name='Dense_Layer'),\n",
    "                          tfpl.DenseVariational(\n",
    "                          units=tfpl.IndependentNormal.params_size(1),\n",
    "                          make_prior_fn=prior_trainable,\n",
    "                          make_posterior_fn=posterior_mean_field,\n",
    "                          kl_weight=1/train_len,\n",
    "                          name='Dense_Variational'),  \n",
    "                          tfpl.IndependentNormal((1,),name='Output_Normal')])\n",
    "    return model\n",
    "\n",
    "\n",
    "def dense_model(inputs=7):\n",
    "    model = keras.Sequential([keras.layers.Input(inputs,name='Input'),  \n",
    "                          keras.layers.Dense(inputs,activation='sigmoid'),\n",
    "                          keras.layers.Dense(6,activation='sigmoid'),  \n",
    "                          keras.layers.Dense(2,activation=None),\n",
    "                          tfpl.IndependentNormal((1,),name='Output_Normal')])\n",
    "    \n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f55db37-0afe-4f2c-a66b-19c0e1001bab",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb3b33e-6c2c-4105-87fb-12d35ff06516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weights(criteria,df):\n",
    "    new_df = df.copy()\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes=criteria.unique(),\n",
    "                                                 y=criteria)\n",
    "    weight_dict = {}\n",
    "    for idx,i in enumerate(criteria.unique()):\n",
    "        weight_dict[i] = class_weights[idx]\n",
    "    for text in criteria.unique():\n",
    "        new_df.loc[criteria == text,'weight'] = weight_dict[text]\n",
    "        \n",
    "    return new_df.pop('weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e38276f-086a-47b1-878a-b50ab0d054bd",
   "metadata": {},
   "source": [
    "##### Dense Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08fe42-aa0c-489d-8038-78a5db7fc96c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables = ['sand','clay','ph','dem','ET','NDVI_500','LST_11','precip','smap']\n",
    "x = train_df.loc[:,variables]\n",
    "y = train_df['in_situ']\n",
    "\n",
    "val_x = test_df.loc[:,variables]\n",
    "val_y = test_df.in_situ\n",
    "histories = {}\n",
    "save_dir = f'Models/new_train/Dense/'\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                                    monitor='val_loss',\n",
    "                                    factor=0.5,\n",
    "                                    patience=15,\n",
    "                                    verbose=0,\n",
    "                                    mode='auto',\n",
    "                                    min_delta=0.01,#0.0005\n",
    "                                    cooldown=0,\n",
    "                                    min_lr=0.0005)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor='val_loss',\n",
    "                                    patience=31,\n",
    "                                    min_delta=0.0005)#0.0002\n",
    "\n",
    "for att in ['texture','sand','clay','koep','mcd12','ph']:\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                '{0}{1}'.format(save_dir,att),\n",
    "                monitor='val_loss',\n",
    "                verbose=0,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                mode='min',\n",
    "                save_freq='epoch',\n",
    "            )\n",
    "    callbacks = [checkpoint,reduce_lr,early_stopping]\n",
    "    weights = create_weights(train_df[att],train_df)\n",
    "    val_weights = create_weights(test_df[att],test_df)\n",
    "    val_data = (val_x,val_y.values,val_weights)\n",
    "    model = dense_model(inputs=x.shape[-1])\n",
    "    model.compile(loss=nll, optimizer=keras.optimizers.Adam(learning_rate=0.1),weighted_metrics=[])\n",
    "    history = model.fit(x=x,y=y,epochs=500,batch_size=8192*2,sample_weight=weights,validation_data=val_data,callbacks=callbacks)\n",
    "    histories[att] = history\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            '{}free_run'.format(save_dir),\n",
    "            monitor='val_loss',\n",
    "            verbose=0,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='min',\n",
    "            save_freq='epoch',\n",
    "        )\n",
    "\n",
    "callbacks = [checkpoint,reduce_lr,early_stopping]\n",
    "val_data = (val_x,val_y.values)\n",
    "model = gen_model(inputs=x.shape[-1],train_len=x.shape[0])\n",
    "model.compile(loss=nll, optimizer=keras.optimizers.Adam(learning_rate=0.1))\n",
    "history = model.fit(x=x,y=y,epochs=500,batch_size=8192*2,validation_data=val_data,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579a4f3-bf77-4342-9541-410114d7a948",
   "metadata": {},
   "source": [
    "##### Prob Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a24e0f-24a7-484d-876b-6b5812ef7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['sand','clay','ph','dem','ET','NDVI_500','LST_11','precip','smap']\n",
    "x = train_df.loc[:,variables]\n",
    "y = train_df['in_situ']\n",
    "\n",
    "val_x = test_df.loc[:,variables]\n",
    "val_y = test_df.in_situ\n",
    "histories = {}\n",
    "save_dir = f'Models/new_train/Prob/'\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                                    monitor='val_loss',\n",
    "                                    factor=0.5,\n",
    "                                    patience=15,\n",
    "                                    verbose=0,\n",
    "                                    mode='auto',\n",
    "                                    min_delta=0.01,#0.0005\n",
    "                                    cooldown=0,\n",
    "                                    min_lr=0.0005)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor='val_loss',\n",
    "                                    patience=31,\n",
    "                                    min_delta=0.0005)#0.0002\n",
    "\n",
    "for att in ['texture','sand','clay','koep','mcd12','ph']:\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                '{0}{1}'.format(save_dir,att),\n",
    "                monitor='val_loss',\n",
    "                verbose=0,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                mode='min',\n",
    "                save_freq='epoch',\n",
    "            )\n",
    "    callbacks = [checkpoint,reduce_lr,early_stopping]\n",
    "    weights = create_weights(train_df[att],train_df)\n",
    "    val_weights = create_weights(test_df[att],test_df)\n",
    "    val_data = (val_x,val_y.values,val_weights)\n",
    "    model = gen_model(inputs=x.shape[-1],train_len=x.shape[0])\n",
    "    model.compile(loss=nll, optimizer=keras.optimizers.Adam(learning_rate=0.1),weighted_metrics=[])\n",
    "    history = model.fit(x=x,y=y,epochs=500,batch_size=8192*2,sample_weight=weights,validation_data=val_data,callbacks=callbacks)\n",
    "    histories[att] = history\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            '{}free_run'.format(save_dir),\n",
    "            monitor='val_loss',\n",
    "            verbose=0,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='min',\n",
    "            save_freq='epoch',\n",
    "        )\n",
    "\n",
    "callbacks = [checkpoint,reduce_lr,early_stopping]\n",
    "val_data = (val_x,val_y.values)\n",
    "model = gen_model(inputs=x.shape[-1],train_len=x.shape[0])\n",
    "model.compile(loss=nll, optimizer=keras.optimizers.Adam(learning_rate=0.1))\n",
    "history = model.fit(x=x,y=y,epochs=500,batch_size=8192*2,validation_data=val_data,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27592b-7c0b-49da-80f0-166e758ebaec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### WDL Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf3122af-fda9-40eb-9d28-e2ced9f149e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.experimental import LinearModel, WideDeepModel\n",
    "\n",
    "cat_dict = {'texture':13,'mcd12':18,'koep':32}\n",
    "\n",
    "def wide_inputs(df,spatial=False):\n",
    "    if spatial:\n",
    "        dnn_in = df.loc[:,['sand','clay','ph','dem','NDVI_250','LST_11','ET','precip','smap']]\n",
    "    else:\n",
    "        dnn_in = df.loc[:,['sand','clay','ph','dem','NDVI_500','LST_11','ET','precip','smap']]\n",
    "    wide_in = dnn_in\n",
    "    cats = df.loc[:,['texture','mcd12','koep']]\n",
    "    cat_embeds = []\n",
    "    for cat in cats.columns:\n",
    "        embedding = np.eye(cat_dict[cat])[cats[cat].astype(int)]\n",
    "        cat_embeds.append(np.asarray(embedding))\n",
    "\n",
    "    embeddings = np.concatenate(cat_embeds,axis=1)\n",
    "    dnn_in = np.concatenate([dnn_in,embeddings],axis=1)\n",
    "    return wide_in.values.astype(float),dnn_in.astype(float)\n",
    "\n",
    "def initialize_models():\n",
    "    linear_model = LinearModel()\n",
    "    dnn_model = keras.Sequential([keras.layers.Dense(units=128,activation='sigmoid',name='dnn_1'),\n",
    "                                 keras.layers.Dense(units=64,activation='sigmoid',name='dnn_2'),\n",
    "                                 keras.layers.Dense(units=1,activation='sigmoid',name='dnn_3')])\n",
    "    return linear_model,dnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1cb80-0037-4241-816d-511d05409bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['sand','clay','ph','dem','ET','NDVI_500','LST_11','precip','smap']\n",
    "wide_x,dnn_x = wide_inputs(train_df)\n",
    "wide_y,dnn_y = wide_inputs(test_df)\n",
    "y = train_df.in_situ\n",
    "val_y = test_df.in_situ\n",
    "val_data = [[wide_y,dnn_y],val_y]\n",
    "save_dir = f'Models/new_train/WDL/'\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                                    monitor='val_loss',\n",
    "                                    factor=0.5,\n",
    "                                    patience=15,\n",
    "                                    verbose=0,\n",
    "                                    mode='auto',\n",
    "                                    min_delta=0.01,#0.0005\n",
    "                                    cooldown=0,\n",
    "                                    min_lr=0.0005)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor='val_loss',\n",
    "                                    patience=31,\n",
    "                                    min_delta=0.0005)#0.0002\n",
    "\n",
    "for att in ['texture','sand','clay','koep','mcd12','ph']:\n",
    "    linear_model,dnn_model = initialize_models()\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                '{0}{1}'.format(save_dir,att),\n",
    "                monitor='val_loss',\n",
    "                verbose=0,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                mode='min',\n",
    "                save_freq='epoch',\n",
    "            )\n",
    "    callbacks = [checkpoint,reduce_lr,early_stopping]\n",
    "    weights = create_weights(train_df[att],train_df)\n",
    "    val_weights = create_weights(test_df[att],test_df)\n",
    "    val_data =  [[wide_y,dnn_y],val_y,val_weights]\n",
    "    model = WideDeepModel(linear_model,dnn_model)\n",
    "    for lr in [0.001,0.0005,0.0001]:\n",
    "        model.compile(optimizer=['sgd',keras.optimizers.Adam(learning_rate=lr)][1],loss='mse',weighted_metrics=[])\n",
    "        history = model.fit([wide_x,dnn_x],y,epochs=500,batch_size=8192*2,sample_weight=weights,validation_data=val_data,callbacks=callbacks)\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            '{}free'.format(save_dir),\n",
    "            monitor='val_loss',\n",
    "            verbose=0,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='min',\n",
    "            save_freq='epoch',\n",
    "        )\n",
    "\n",
    "linear_model,dnn_model = initialize_models()\n",
    "callbacks = [checkpoint,reduce_lr,early_stopping]\n",
    "val_data = [[wide_y,dnn_y],val_y]\n",
    "model = WideDeepModel(linear_model,dnn_model)\n",
    "for lr in [0.001,0.0005,0.0001]:\n",
    "    model.compile(optimizer=['sgd',keras.optimizers.Adam(learning_rate=lr)][1],loss='mse')\n",
    "    history = model.fit([wide_x,dnn_x],y,epochs=500,batch_size=8192*2,validation_data=val_data,callbacks=callbacks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
